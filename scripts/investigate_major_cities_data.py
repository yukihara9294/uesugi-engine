#!/usr/bin/env python3
"""
ç¦å²¡çœŒãƒ»å¤§é˜ªåºœãƒ»æ±äº¬éƒ½ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
å„è‡ªæ²»ä½“ã®ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«ã‚µã‚¤ãƒˆã¨APIã®å¯ç”¨æ€§ã‚’ç¢ºèª
"""
import requests
import json
from datetime import datetime
from pathlib import Path
import logging

# ãƒ­ã‚®ãƒ³ã‚°è¨­å®š
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


class MajorCitiesDataInvestigator:
    """ä¸»è¦éƒ½å¸‚ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«èª¿æŸ»"""
    
    def __init__(self):
        self.base_dir = Path(__file__).parent.parent
        self.report_dir = self.base_dir / "uesugi-engine-data" / "investigation_reports"
        self.report_dir.mkdir(parents=True, exist_ok=True)
        
        # èª¿æŸ»å¯¾è±¡ã®éƒ½å¸‚ã¨ãã®ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«æƒ…å ±
        self.cities = {
            "fukuoka": {
                "name": "ç¦å²¡çœŒ",
                "portal_url": "https://ckan.open-governmentdata.org/",
                "api_base": "https://ckan.open-governmentdata.org/api/3/action",
                "alternative_urls": [
                    "https://www.open-governmentdata.org/fukuoka-pref/",
                    "https://data.bodik.jp/"  # BODIKï¼ˆä¹å·ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æ¨é€²ä¼šè­°ï¼‰
                ],
                "notes": "ç¦å²¡çœŒã¯BODIKï¼ˆä¹å·ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿æ¨é€²ä¼šè­°ï¼‰ã‚‚æ´»ç”¨"
            },
            "osaka": {
                "name": "å¤§é˜ªåºœ",
                "portal_url": "https://www.pref.osaka.lg.jp/kikaku_keikaku/opendata/",
                "api_base": None,  # èª¿æŸ»äºˆå®š
                "alternative_urls": [
                    "https://data.city.osaka.lg.jp/",  # å¤§é˜ªå¸‚ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«
                    "https://www.city.sakai.lg.jp/shisei/tokei/opendata/"  # å ºå¸‚
                ],
                "notes": "å¤§é˜ªåºœãƒ»å¤§é˜ªå¸‚ãƒ»å ºå¸‚ãªã©è¤‡æ•°ã®ãƒãƒ¼ã‚¿ãƒ«ãŒå­˜åœ¨"
            },
            "tokyo": {
                "name": "æ±äº¬éƒ½",
                "portal_url": "https://portal.data.metro.tokyo.lg.jp/",
                "api_base": "https://portal.data.metro.tokyo.lg.jp/api/3/action",
                "alternative_urls": [
                    "https://catalog.data.metro.tokyo.lg.jp/",
                    "https://www.opendata.metro.tokyo.lg.jp/"
                ],
                "notes": "æ±äº¬éƒ½ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ã‚«ã‚¿ãƒ­ã‚°ã‚µã‚¤ãƒˆï¼ˆCKANï¼‰"
            }
        }
        
    def check_ckan_api(self, api_base):
        """CKAN APIã®å¯ç”¨æ€§ã‚’ãƒã‚§ãƒƒã‚¯"""
        try:
            # ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã§ãƒ†ã‚¹ãƒˆ
            response = requests.get(f"{api_base}/package_list", timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get("success"):
                    package_count = len(data.get("result", []))
                    return {
                        "available": True,
                        "package_count": package_count,
                        "requires_auth": False
                    }
            return {"available": False, "error": f"Status code: {response.status_code}"}
        except Exception as e:
            return {"available": False, "error": str(e)}
            
    def search_tourism_data(self, api_base):
        """è¦³å…‰é–¢é€£ãƒ‡ãƒ¼ã‚¿ã‚’æ¤œç´¢"""
        try:
            keywords = ["è¦³å…‰", "å®¿æ³Š", "ã‚¤ãƒ™ãƒ³ãƒˆ", "tourism"]
            results = []
            
            for keyword in keywords:
                response = requests.get(
                    f"{api_base}/package_search",
                    params={"q": keyword, "rows": 10},
                    timeout=10
                )
                
                if response.status_code == 200:
                    data = response.json()
                    if data.get("success"):
                        for package in data["result"]["results"]:
                            results.append({
                                "title": package.get("title", ""),
                                "name": package.get("name", ""),
                                "notes": package.get("notes", "")[:100] + "..."
                            })
                            
            return results[:20]  # æœ€å¤§20ä»¶
        except Exception as e:
            logger.error(f"æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {e}")
            return []
            
    def investigate_city(self, city_key):
        """éƒ½å¸‚ã®ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«ã‚’èª¿æŸ»"""
        city = self.cities[city_key]
        logger.info(f"\n{'='*60}")
        logger.info(f"{city['name']}ã®ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«èª¿æŸ»")
        logger.info(f"{'='*60}")
        
        report = {
            "city": city["name"],
            "timestamp": datetime.now().isoformat(),
            "portal_url": city["portal_url"],
            "api_status": None,
            "sample_datasets": [],
            "recommendations": []
        }
        
        # APIãƒã‚§ãƒƒã‚¯
        if city["api_base"]:
            logger.info(f"APIç¢ºèªä¸­: {city['api_base']}")
            api_status = self.check_ckan_api(city["api_base"])
            report["api_status"] = api_status
            
            if api_status["available"]:
                logger.info(f"âœ… APIåˆ©ç”¨å¯èƒ½ï¼ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•°: {api_status['package_count']}")
                
                # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æ¤œç´¢
                sample_data = self.search_tourism_data(city["api_base"])
                report["sample_datasets"] = sample_data
                logger.info(f"è¦³å…‰é–¢é€£ãƒ‡ãƒ¼ã‚¿: {len(sample_data)}ä»¶ç™ºè¦‹")
                
                # æ¨å¥¨äº‹é …
                report["recommendations"].append(
                    f"CKAN APIãŒåˆ©ç”¨å¯èƒ½ã€‚collect_yamaguchi_data_v2.pyã‚’ãƒ™ãƒ¼ã‚¹ã«{city['name']}ç‰ˆã‚’ä½œæˆå¯èƒ½"
                )
            else:
                logger.warning(f"âŒ APIåˆ©ç”¨ä¸å¯: {api_status.get('error', 'Unknown error')}")
                report["recommendations"].append(
                    "CKAN APIãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯ã€æ‰‹å‹•ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã‚¹ã‚¯ãƒªãƒ—ãƒˆã‚’æ¤œè¨"
                )
        else:
            logger.info("APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆæœªç¢ºèª")
            report["recommendations"].append(
                "APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã®èª¿æŸ»ãŒå¿…è¦ã€‚ãƒãƒ¼ã‚¿ãƒ«ã‚µã‚¤ãƒˆã§API documentationã‚’ç¢ºèª"
            )
            
        # ä»£æ›¿URLæƒ…å ±
        report["alternative_sources"] = city.get("alternative_urls", [])
        report["notes"] = city.get("notes", "")
        
        return report
        
    def generate_collection_script_template(self, city_key):
        """ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        city = self.cities[city_key]
        template_path = self.report_dir / f"collect_{city_key}_data_template.py"
        
        template = f'''#!/usr/bin/env python3
"""
{city['name']}ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿åé›†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
è‡ªå‹•ç”Ÿæˆãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ - è¦ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚º
"""
import requests
import json
from datetime import datetime
from pathlib import Path
import logging

# åŸºæœ¬è¨­å®š
CITY_NAME = "{city['name']}"
API_BASE = "{city.get('api_base', 'TODO: APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆã‚’è¨­å®š')}"
PORTAL_URL = "{city['portal_url']}"

class {city_key.capitalize()}DataCollector:
    def __init__(self):
        self.api_base = API_BASE
        self.data_dir = Path("uesugi-engine-data/{city_key}")
        self.data_dir.mkdir(parents=True, exist_ok=True)
        
    def collect_data(self):
        # TODO: å®Ÿè£…
        pass

if __name__ == "__main__":
    collector = {city_key.capitalize()}DataCollector()
    collector.collect_data()
'''
        
        with open(template_path, 'w', encoding='utf-8') as f:
            f.write(template)
            
        return template_path
        
    def run_investigation(self):
        """å…¨éƒ½å¸‚ã®èª¿æŸ»ã‚’å®Ÿè¡Œ"""
        all_reports = {}
        
        for city_key in self.cities:
            report = self.investigate_city(city_key)
            all_reports[city_key] = report
            
            # ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ
            if report["api_status"] and report["api_status"]["available"]:
                template_path = self.generate_collection_script_template(city_key)
                logger.info(f"ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆç”Ÿæˆ: {template_path}")
                
        # ç·åˆãƒ¬ãƒãƒ¼ãƒˆä½œæˆ
        self.save_investigation_report(all_reports)
        
        return all_reports
        
    def save_investigation_report(self, all_reports):
        """èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSONå½¢å¼
        json_path = self.report_dir / f"major_cities_investigation_{timestamp}.json"
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(all_reports, f, ensure_ascii=False, indent=2)
            
        # ãƒ†ã‚­ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ
        report_path = self.report_dir / f"major_cities_investigation_{timestamp}.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("# ä¸»è¦éƒ½å¸‚ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ\n\n")
            f.write(f"å®Ÿæ–½æ—¥æ™‚: {datetime.now()}\n\n")
            
            for city_key, report in all_reports.items():
                f.write(f"## {report['city']}\n\n")
                f.write(f"- **ãƒãƒ¼ã‚¿ãƒ«URL**: {report['portal_url']}\n")
                
                if report['api_status']:
                    f.write(f"- **APIçŠ¶æ…‹**: {'âœ… åˆ©ç”¨å¯èƒ½' if report['api_status']['available'] else 'âŒ åˆ©ç”¨ä¸å¯'}\n")
                    if report['api_status'].get('package_count'):
                        f.write(f"- **ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆæ•°**: {report['api_status']['package_count']}ä»¶\n")
                        
                if report['sample_datasets']:
                    f.write(f"\n### ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆè¦³å…‰é–¢é€£ï¼‰\n")
                    for ds in report['sample_datasets'][:5]:
                        f.write(f"- {ds['title']}\n")
                        
                if report['alternative_sources']:
                    f.write(f"\n### ä»£æ›¿ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹\n")
                    for url in report['alternative_sources']:
                        f.write(f"- {url}\n")
                        
                if report['recommendations']:
                    f.write(f"\n### æ¨å¥¨äº‹é …\n")
                    for rec in report['recommendations']:
                        f.write(f"- {rec}\n")
                        
                f.write(f"\n---\n\n")
                
        logger.info(f"\nğŸ“„ èª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜å®Œäº†:")
        logger.info(f"- JSON: {json_path}")
        logger.info(f"- Markdown: {report_path}")
        
        return json_path, report_path


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("\nğŸ” ä¸»è¦éƒ½å¸‚ã‚ªãƒ¼ãƒ—ãƒ³ãƒ‡ãƒ¼ã‚¿ãƒãƒ¼ã‚¿ãƒ«èª¿æŸ»é–‹å§‹")
    print("å¯¾è±¡: ç¦å²¡çœŒã€å¤§é˜ªåºœã€æ±äº¬éƒ½")
    print("="*60)
    
    investigator = MajorCitiesDataInvestigator()
    reports = investigator.run_investigation()
    
    print("\nğŸ“Š èª¿æŸ»ã‚µãƒãƒªãƒ¼:")
    for city_key, report in reports.items():
        print(f"\nã€{report['city']}ã€‘")
        if report['api_status']:
            if report['api_status']['available']:
                print(f"âœ… CKAN APIåˆ©ç”¨å¯èƒ½ - {report['api_status']['package_count']}ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ")
            else:
                print(f"âŒ APIåˆ©ç”¨ä¸å¯")
        else:
            print("âš ï¸ APIæœªèª¿æŸ»")
            
        print(f"ä»£æ›¿ã‚½ãƒ¼ã‚¹: {len(report.get('alternative_sources', []))}ä»¶")


if __name__ == "__main__":
    main()